{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bdff8e-7de9-495b-8a12-5aa911e0e25a",
   "metadata": {},
   "source": [
    "## Exploring the GPT Chat Completion Model\n",
    "\n",
    "In this notebook, I delve into the workings of a standard GPT chat completion model, evaluating both its advantages and disadvantages.\n",
    "\n",
    "## Advantages:\n",
    "\n",
    "### 1. Simple and Understandable Code:\n",
    "   The implementation of the GPT chat completion model is characterized by its simplicity and ease of understanding. The code is designed to be accessible, making it suitable for users at various levels of familiarity with natural language processing.\n",
    "\n",
    "### 2. Efficient with Small Prompts:\n",
    "   Despite its concise prompts, the model exhibits remarkable efficiency. It consistently provides accurate and contextually relevant completions, demonstrating its ability to understand and respond effectively to limited input.\n",
    "\n",
    "### 3. High Accuracy:\n",
    "   Notably, the GPT chat completion model boasts high accuracy. The generated responses are contextually coherent, showcasing the model's proficiency in capturing the nuances of language and producing meaningful outputs.\n",
    "\n",
    "## Disadvantages:\n",
    "\n",
    "### 1. Costly:\n",
    "   One significant drawback is the associated cost of utilizing this GPT model. Implementing this model may incur substantial expenses, especially for projects with extensive usage. Users should be mindful of the financial implications when opting for this solution.\n",
    "\n",
    "### 2. Token Limitation:\n",
    "   Another limitation to consider is the constraint on the number of tokens that can be processed in a single request. If the input surpasses this token limit, it may result in errors, necessitating careful management of prompt length to avoid unexpected disruptions.\n",
    "\n",
    "In summary, the GPT chat completion model exhibits simplicity, accuracy, and efficiency with concise prompts. However, users should carefully consider the cost implications and token limitations to determine the model's suitability for specific use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b15a81-834c-416b-939a-c0f086fb4787",
   "metadata": {},
   "source": [
    "### Instaling the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd847b77-260d-4059-a974-98b7508f6fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tiktoken openai pinecone-client langchain\n",
    "# !pip install pypdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a7416-71bf-4a02-9309-e26e2b1c69f0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "79967388-7e69-42ad-8087-196fd29c26d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import openai\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "openai.api_key =input('Enter your gpt api key here:--->')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051461a-406e-4193-a171-259fc64494bf",
   "metadata": {},
   "source": [
    "### Code Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3ba7953d-6f0c-47ba-9500-3f896d91ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the file format and reading it.\n",
    "def process_docs(file_path):\n",
    "    documents = []\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "    elif file_path.lower().endswith('.docx') or file_path.lower().endswith('.doc'):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "26c7f436-a1cd-464f-9b46-a8fc927ce354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_way_gpt(list_page):\n",
    "    completion = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"\"\"Given the following resume, please parse it and provide the extracted information in a **Structured JSON format**. Ensure the JSON includes details such as personal information, education history, skills, summary, and work history.\n",
    "      Example:Example:\n",
    "    {\n",
    "        \"address\": {\n",
    "            \"city\": \"Specify City\",\n",
    "            \"country\": \"Specify Country Code\",\n",
    "            \"state\": \"Specify State Abbreviation\"\n",
    "        },\n",
    "        \"education_history\": [\n",
    "            {\n",
    "                \"degree\": \"Specify Degree\",\n",
    "                \"from_date\": \"Specify Start Date\",\n",
    "                \"name\": \"Specify School/Institute Name\",\n",
    "                \"to_date\": \"Specify End Date\"\n",
    "            }\n",
    "        ],\n",
    "        \"email\": \"Specify Email\",\n",
    "        \"first_name\": \"Specify First Name\",\n",
    "        \"last_name\": \"Specify Last Name\",\n",
    "        \"phone\": \"Specify Phone Number\",\n",
    "        \"skills\": [\n",
    "            {\"skill\": \"Specify Skill 1\"},\n",
    "             ...]}\n",
    "             \"work_history\": [\n",
    "        {\n",
    "            \"company\": \"Company name 1\",\n",
    "            \"description\":\"All work done\"\n",
    "            \"from_date\": \"Start Date\",\n",
    "            \"title\": \"Job Title\",\n",
    "            \"to_date\": \"End \"}\"\"\"},\n",
    "      {\"role\": \"user\", \"content\":'\\n'.join(list_page)}\n",
    "        ]\n",
    "      )\n",
    "    conversation=dict(completion.choices[0].message)['content']\n",
    "    return coversation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "279e5a68-2d5e-4ec9-b538-94d4c9e420f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = \"/home/shivi/Desktop/resume-parser\"\n",
    "for file_name in os.listdir(DIR_PATH):\n",
    "    file_path = os.path.join(DIR_PATH, file_name)\n",
    "    processed_documents = process_docs(file_path)\n",
    "    list_page=[]\n",
    "    for i in processed_documents:\n",
    "        list_page.append(i.page_content)\n",
    "    convo=conversation.splitlines()\n",
    "    resume_data_str = '\\n'.join(convo)\n",
    "    resume_data_str=resume_data_str.replace('```json\\n','').replace('\\n```','')\n",
    "    resume_data = json.loads(resume_data_str)\n",
    "    modified_skills = [{\"skill\": skill.strip('\\\"')} for skill in resume_data[\"skills\"]]\n",
    "    resume_data[\"skills\"] = modified_skills\n",
    "    file_path_save_json= os.path.join(\"/home/shivi/Desktop/parsed_resume\", file_name.split('.')[0]+\".json\")\n",
    "    with open(file_path_save_json, \"w\") as json_file:\n",
    "        json.dump(resume_data, json_file, indent=4)\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
